{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/k_/559_7kh91xgfmdkgt0c3cb000000gn/T/ipykernel_48269/1431081360.py\", line 23, in <module>\n",
      "    from models.clustering.logistic_regression_leiden_clusters import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/clustering/logistic_regression_leiden_clusters.py\", line 15, in <module>\n",
      "    from models.visualization.clusters import cluster_circular, plot_confusion_matrix_lr\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/clusters.py\", line 14, in <module>\n",
      "    from models.visualization.attention_maps import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/attention_maps.py\", line 5, in <module>\n",
      "    from models.utils import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/utils.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 46, in <module>\n",
      "    from tensorflow.python import pywrap_tfe\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/pywrap_tfe.py\", line 25, in <module>\n",
      "    from tensorflow.python._pywrap_tfe import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/k_/559_7kh91xgfmdkgt0c3cb000000gn/T/ipykernel_48269/1431081360.py\", line 23, in <module>\n",
      "    from models.clustering.logistic_regression_leiden_clusters import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/clustering/logistic_regression_leiden_clusters.py\", line 15, in <module>\n",
      "    from models.visualization.clusters import cluster_circular, plot_confusion_matrix_lr\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/clusters.py\", line 14, in <module>\n",
      "    from models.visualization.attention_maps import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/attention_maps.py\", line 5, in <module>\n",
      "    from models.utils import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/utils.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 49, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/k_/559_7kh91xgfmdkgt0c3cb000000gn/T/ipykernel_48269/1431081360.py\", line 23, in <module>\n",
      "    from models.clustering.logistic_regression_leiden_clusters import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/clustering/logistic_regression_leiden_clusters.py\", line 15, in <module>\n",
      "    from models.visualization.clusters import cluster_circular, plot_confusion_matrix_lr\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/clusters.py\", line 14, in <module>\n",
      "    from models.visualization.attention_maps import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/attention_maps.py\", line 5, in <module>\n",
      "    from models.utils import *\n",
      "  File \"/Users/michaelguglielmo/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/utils.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 50, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/framework/dtypes.py\", line 21, in <module>\n",
      "    import ml_dtypes\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ml_dtypes/__init__.py\", line 32, in <module>\n",
      "    from ml_dtypes._finfo import finfo\n",
      "  File \"/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ml_dtypes/_finfo.py\", line 19, in <module>\n",
      "    from ml_dtypes._ml_dtypes_ext import bfloat16\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[31mImportError\u001b[39m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m main_path = \u001b[38;5;28mstr\u001b[39m(Path.cwd().resolve().parent.parent) \n\u001b[32m     22\u001b[39m sys.path.append(main_path)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogistic_regression_leiden_clusters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfolds\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_existing_split\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorrelations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/clustering/logistic_regression_leiden_clusters.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mforest_plots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m report_forest_plot_lr\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclusters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_circular, plot_confusion_matrix_lr\n\u001b[32m     17\u001b[39m \u001b[33;03m''' ############## Combine cluster coefficients ############## '''\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Summarize results for the LR run with same cluster fold.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/clusters.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Own libs\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mattention_maps\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mleiden_representations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m include_tile_connections_frame\n\u001b[32m     17\u001b[39m \u001b[33;03m''' ######  Cluster Summary CircularPlot ######### '''\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/visualization/attention_maps.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Reset coordinates.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code Projects/Histomorphological-Phenotype-Learning/models/utils.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshutil\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/__init__.py:45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     43\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     25\u001b[39m stacks = threading.local()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/eager/context.py:37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cancellation\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m executor\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_conversion_registry\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/tensorflow/python/framework/dtypes.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Type, Sequence, Optional\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ml_dtypes/__init__.py:32\u001b[39m\n\u001b[32m     16\u001b[39m __all__ = [\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbfloat16\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33muint4\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     28\u001b[39m ]\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Type\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_finfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m finfo\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_iinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iinfo\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/HPL/lib/python3.11/site-packages/ml_dtypes/_finfo.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Overload of numpy.finfo to handle dtypes defined in ml_dtypes.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3b11fnuz\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_dtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3fn\n",
      "\u001b[31mImportError\u001b[39m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "from matplotlib        import collections             as matcoll\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from matplotlib.pyplot import rc_context\n",
    "from scipy.cluster     import hierarchy\n",
    "from adjustText        import adjust_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "main_path = str(Path.cwd().resolve().parent.parent) \n",
    "sys.path.append(main_path)\n",
    "from models.clustering.logistic_regression_leiden_clusters import *\n",
    "from models.evaluation.folds import load_existing_split\n",
    "from models.clustering.correlations import *\n",
    "from models.clustering.data_processing import *\n",
    "from models.clustering.leiden_representations import include_tile_connections_frame\n",
    "from data_manipulation.utils import store_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_histo_annotation_df(h5_hist_anno_path, additional_df):\n",
    "    with h5py.File(h5_hist_anno_path, 'r') as content:\n",
    "        slides   = [slide.decode(\"utf-8\").split('_')[0] for slide in content['combined_slides']]\n",
    "        tiles    = [tile.decode(\"utf-8\").split('.')[0] for tile in content['combined_tiles']]\n",
    "        histtype = [type_.decode(\"utf-8\") for type_ in content['combined_hist_subtype']]\n",
    "        histo_df = pd.DataFrame(slides, columns=['slides'])\n",
    "        histo_df['tiles'] = tiles\n",
    "        histo_df['histtype'] = histtype\n",
    "\n",
    "    selected_anno = ['acinar', 'lepidic', 'micropapillary', 'papillary', 'solid']\n",
    "\n",
    "    additional_df['slides'] = additional_df['slides'].astype(str)\n",
    "    histo_complete_df = additional_df.merge(histo_df, how='inner', left_on=['slides','tiles'], right_on=['slides','tiles'])\n",
    "    histo_complete_df = histo_complete_df.loc[histo_complete_df['histtype'].isin(selected_anno)]\n",
    "\n",
    "    return histo_complete_df\n",
    "\n",
    "\n",
    "def get_col_colors(cox_os_clusters, cox_pfs_clusters, p_th):\n",
    "    colors        = None\n",
    "    colors_masked = None\n",
    "    if cox_os_clusters is not None:\n",
    "        # Column colors.\n",
    "        coef_df   = cox_os_clusters.sort_values(by=groupby)\n",
    "        cmap_PiYG = plt.cm.PiYG_r\n",
    "        norm      = TwoSlopeNorm(vmin=coef_df['coef'].min(), vcenter=0, vmax=coef_df['coef'].max())\n",
    "        column_os_colors              = pd.Series([cmap_PiYG(norm(coef)) for p, coef in zip(coef_df['p'], coef_df['coef'])], name='Cox Coefficient Overall Survival')\n",
    "        column_os_colors_masked       = pd.Series([cmap_PiYG(norm(coef)) if p <p_th else cmap_PiYG(norm(0))[:3] for p, coef in zip(coef_df['p'], coef_df['coef'])], name='Cox Coefficient Overall Survival')\n",
    "        column_os_colors_masked.index = coef_df[groupby].astype(str)\n",
    "        column_os_colors.index        = coef_df[groupby].astype(str)\n",
    "        colors        = column_os_colors\n",
    "        colors_masked = column_os_colors_masked\n",
    "\n",
    "        if cox_pfs_clusters is not None:\n",
    "            cox_pfs_clusters = cox_pfs_clusters.sort_values(by=groupby)\n",
    "            cmap_PiYG = plt.cm.PiYG_r\n",
    "            norm                     = TwoSlopeNorm(vmin=cox_pfs_clusters['coef'].astype(float).min(), vcenter=0, vmax=cox_pfs_clusters['coef'].astype(float).max())\n",
    "            column_pfs_colors        = pd.Series([cmap_PiYG(norm(coef)) for p, coef in zip(cox_pfs_clusters['p'], cox_pfs_clusters['coef'])], name='Cox Coefficient\\nRecurrence Free Survival')\n",
    "            column_pfs_colors_masked = pd.Series([cmap_PiYG(norm(coef)) if p <p_th else cmap_PiYG(norm(0))[:3] for p, coef in zip(cox_pfs_clusters['p'], cox_pfs_clusters['coef'])], name='Cox Coefficient\\nProgression Free Survival')\n",
    "            column_pfs_colors.index        = coef_df[groupby].astype(str)\n",
    "            column_pfs_colors_masked.index = coef_df[groupby].astype(str)\n",
    "\n",
    "            colors = pd.concat([column_os_colors, column_pfs_colors],axis=1)\n",
    "            colors_masked = pd.concat([column_os_colors_masked, column_pfs_colors_masked],axis=1)\n",
    "\n",
    "    return colors, colors_masked\n",
    "\n",
    "\n",
    "def plot_clustermap(all_data_rho, mask, x_label, y_label, directory, file_name, figsize, vcenter=0, annot=True, fmt='.2f', cox_os_clusters=None, cox_pfs_clusters=None, col_linkage=None, row_linkage=None, fontsize_ticks=28, fontsize_labels=30, fontsize_annot=20, dendrogram_ratio=0.2, row_colors_same=False, show=False, not_masked=False, p_th=0.01):\n",
    "\n",
    "    if col_linkage is None:\n",
    "        Z = hierarchy.linkage(y=all_data_rho.T, method='ward', metric='euclidean', optimal_ordering=False)\n",
    "        col_linkage = Z\n",
    "\n",
    "    colors, colors_masked = get_col_colors(cox_os_clusters, cox_pfs_clusters, p_th)\n",
    "    with rc_context({'figure.figsize': figsize}):\n",
    "\n",
    "        for name, col_colors in [('', colors), ('_masked', colors_masked)]:\n",
    "            if 'masked' in name and not_masked:\n",
    "                continue\n",
    "            sns.set_theme(style='white')\n",
    "            vref = np.max(np.abs(all_data_rho.values))\n",
    "            if vcenter == 0:\n",
    "                norm = TwoSlopeNorm(vmin=-vref, vcenter=vcenter, vmax=vref)\n",
    "            else:\n",
    "                norm = TwoSlopeNorm(vmin=all_data_rho.values.min(), vcenter=vcenter, vmax=all_data_rho.values.max())\n",
    "\n",
    "            row_colors = None\n",
    "            if row_colors_same:\n",
    "                row_colors = col_colors\n",
    "\n",
    "            g = sns.clustermap(all_data_rho, vmin=-vref, vmax=vref, method='ward', metric='euclidean', annot=annot, mask=mask, col_colors=col_colors, row_colors=row_colors, col_linkage=col_linkage, row_linkage=row_linkage, fmt=fmt, norm=norm, cmap=sns.diverging_palette(250, 20, as_cmap=True), dendrogram_ratio=dendrogram_ratio, annot_kws={\"size\": fontsize_annot},  yticklabels=True,  xticklabels=True)\n",
    "\n",
    "            if col_colors is not None:\n",
    "                g.ax_col_colors.set_yticklabels(g.ax_col_colors.get_ymajorticklabels(), fontsize=fontsize_ticks)\n",
    "            if row_colors_same:\n",
    "                g.ax_row_colors.set_xticklabels(g.ax_row_colors.get_xmajorticklabels(), fontsize=fontsize_ticks)\n",
    "\n",
    "            g.ax_heatmap.set_ylabel('\\n%s' % y_label, fontsize=fontsize_labels)\n",
    "            g.ax_heatmap.set_xlabel('\\n%s' % x_label, fontsize=fontsize_labels)\n",
    "            g._figure.set_size_inches(figsize[0]*1.1, figsize[1]*1.1)\n",
    "            g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xmajorticklabels(), fontsize=fontsize_ticks)\n",
    "            g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_ymajorticklabels(), fontsize=fontsize_ticks)\n",
    "            g.ax_cbar.tick_params(labelsize=fontsize_ticks)\n",
    "            if show:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig('%s/%s' % (directory, file_name.replace('.jpg', '%s.jpg' % name)))\n",
    "                plt.close(g._figure)\n",
    "\n",
    "            if col_colors is None:\n",
    "                break\n",
    "    return g\n",
    "\n",
    "def plot_dendrogram(adata, groupby, directory=None, file_name=None, show=False):\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    fig.suptitle('Leiden Cluster Dendrogram')\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax = sc.pl.dendrogram(adata, groupby=groupby, ax=ax, show=show)\n",
    "    if directory is not None and file_name is not None:\n",
    "        plt.savefig(os.path.join(directory, file_name))\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variables for run comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Workspace path.\n",
    "main_path = '/media/adalberto/Disk2/PhD_Workspace'\n",
    "\n",
    "'''\n",
    "LUAD Survival\n",
    "resolution     = 2.0\n",
    "fold_number    = 0\n",
    "alpha          = 1.0\n",
    "alpha_2        = 1.0\n",
    "\n",
    "resolution     = 1.0\n",
    "fold_number    = 0\n",
    "alpha          = None\n",
    "alpha_2        = None\n",
    "\n",
    "'''\n",
    "\n",
    "# Resolution and fold for the tile clustering and slide representations.\n",
    "resolution     = 2.0\n",
    "fold_number    = 0\n",
    "groupby        = 'leiden_%s' % resolution\n",
    "\n",
    "# Folder run.\n",
    "meta_folder     = 'luad_overall_survival_nn250_clusterfold%s' % fold_number\n",
    "matching_field  = 'samples'\n",
    "meta_field      = 'os_event_ind'\n",
    "# meta_field      = 'luad'\n",
    "\n",
    "# HoverNet dataset annotations.\n",
    "cell_names             = ['cell neoplastic', 'cell inflammatory', 'cell connective', 'cell dead']\n",
    "dataset = 'TCGAFFPE_LUADLUSC_5x_10pc'\n",
    "magnification          = '20x'\n",
    "annotation_restriction = 1\n",
    "\n",
    "# Penalties for Cox regression and flag for usage.\n",
    "use_cox        = True\n",
    "alpha          = 1.0\n",
    "alpha_2        = None\n",
    "\n",
    "# Pickle files.\n",
    "# folds_pickle = '%s/utilities/files/LUADLUSC/lungsubtype_Institutions.pkl' % main_path\n",
    "folds_pickle = '%s/utilities/files/LUAD/overall_survival_TCGA_folds.pkl'  % main_path\n",
    "\n",
    "# Tile representation files.\n",
    "h5_complete_path   = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/hdf5_TCGAFFPE_LUADLUSC_5x_60pc_he_complete_lungsubtype_survival_filtered.h5' % main_path\n",
    "h5_additional_path = None\n",
    "\n",
    "# Annotation files.\n",
    "hovernet_csv     = '%s/datasets/HoverNet/%s/%s/%s_hovernet_annotations_5x.csv' % (main_path, dataset, magnification, dataset)\n",
    "tcga_immune_csv  = '%s/utilities/files/TCGA/TCGA_immune_landscape.csv' % main_path\n",
    "\n",
    "# Run path.\n",
    "main_cluster_path = h5_complete_path.split('hdf5_')[0]\n",
    "main_cluster_path = os.path.join(main_cluster_path, meta_folder)\n",
    "adatas_path       = os.path.join(main_cluster_path, 'adatas')\n",
    "figure_path       = os.path.join(main_cluster_path, 'leiden_%s_fold%s' % (str(resolution).replace('.','p'),fold_number))\n",
    "figure_path       = os.path.join(figure_path,       'figures')\n",
    "if not os.path.isdir(figure_path):\n",
    "    os.makedirs(figure_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cox Regression runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Cox run for coefficients.\n",
    "coef_os_df  = None\n",
    "coef_pfs_df = None\n",
    "if use_cox:\n",
    "    csv_cox = os.path.join(main_cluster_path, '%s_leiden_%s_alpha_%s_l1ratio_0p0_mintiles_100' % (meta_folder, resolution, str(alpha).replace('.','p')))\n",
    "    csv_cox = os.path.join(csv_cox, 'leiden_%s_stats_all_folds.csv' % (str(resolution).replace('.','p')))\n",
    "\n",
    "    # Read in regression coefficient file\n",
    "    cox_df  = pd.read_csv(csv_cox)\n",
    "    coef_os_df = cox_df[[groupby, 'coef', 'p']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Immune landscape sample annotations.\n",
    "immune_landscape_df = pd.read_csv(tcga_immune_csv)\n",
    "\n",
    "# HoverNet Annotations.\n",
    "hovernet_df  = pd.read_csv(hovernet_csv)\n",
    "if '.' in hovernet_df.slides.astype(str).values[0]:\n",
    "    hovernet_df['slides'] = [slide.split('.')[0] for slide in hovernet_df.slides if '.' in slide ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Representations: Slides and Tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' Get representations for slide representation correlations. '''\n",
    "# Fold\n",
    "folds = load_existing_split(folds_pickle)\n",
    "fold = folds[fold_number]\n",
    "\n",
    "# Read cohort CSVs.\n",
    "dataframes, complete_df, leiden_clusters   = read_csvs(adatas_path, matching_field, groupby, fold_number, fold, h5_complete_path, h5_additional_path, additional_as_fold=False, force_fold=None)\n",
    "train_df, valid_df, test_df, additional_df = dataframes\n",
    "complete_df['tiles']   = complete_df['tiles'].apply(lambda x: x.split('.jpeg')[0])\n",
    "if additional_df is not None:\n",
    "    additional_df['tiles'] = additional_df['tiles'].apply(lambda x: x.split('.jpeg')[0])\n",
    "\n",
    "annotated_df           = complete_df.merge(hovernet_df, how='inner', left_on=['slides', 'tiles'], right_on=['slides', 'tiles'])\n",
    "cluster_anno_df        = annotated_df[annotated_df['annotated_20x_tile_count']>=annotation_restriction]\n",
    "\n",
    "''' Get representations for slide representation correlations. '''\n",
    "frames = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path, 'clr', 100)\n",
    "complete_df, additional_complete_df, frame_clusters, frame_samples, features = frames\n",
    "complete_df.columns            = complete_df.columns.astype(str)\n",
    "if additional_complete_df is not None:\n",
    "    if matching_field == 'samples' and matching_field not in additional_complete_df.columns:\n",
    "        additional_complete_df[matching_field] = additional_complete_df['slides']\n",
    "    additional_complete_df.columns = additional_complete_df.columns.astype(str)\n",
    "# # Check for duplicates, ways of handling them:\n",
    "# # 1. Drop duplicates.\n",
    "# # 2. Combine slides into representations: This may include coming back from CLR and back after merged.\n",
    "# if len(np.unique(complete_df.samples)) != complete_df.shape[0]:\n",
    "#     # Easy option 1.\n",
    "#     complete_df = complete_df.drop_duplicates(subset='samples', keep=\"last\")\n",
    "\n",
    "''' Read clustering file '''\n",
    "adata_train, h5ad_path = read_h5ad_reference(h5_complete_path, meta_folder, groupby, fold_number)\n",
    "\n",
    "# Leiden clusters dendrogram.\n",
    "leiden_linkage_method = 'average'\n",
    "leiden_cor_method     = 'spearman'\n",
    "sc.tl.dendrogram(adata_train, groupby, use_rep='X', linkage_method=leiden_linkage_method, cor_method=leiden_cor_method)\n",
    "leiden_linkage = adata_train.uns['dendrogram_%s' % groupby]['linkage']\n",
    "\n",
    "''' Prepare manual annotations for histological subtypes.'''\n",
    "if additional_df is not None:\n",
    "    histo_complete_df  = create_histo_annotation_df(h5_hist_anno_path, additional_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corr_method   = 'spearman'   # Correlation method.\n",
    "corr_matching = 'samples'\n",
    "pval_th       = 0.01\n",
    "\n",
    "correlations_dict = dict()\n",
    "\n",
    "''' Leiden Cluster Dendrogram'''\n",
    "file_name = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s_%s_leiden_dendrogram' % (groupby.replace('.', 'p'), fold_number, meta_folder)\n",
    "sc.tl.dendrogram(adata_train, groupby=groupby, cor_method='pearson', linkage_method='average', optimal_ordering=True)\n",
    "correlations_dict[groupby] = dict()\n",
    "correlations_dict[groupby]['file_name'] = file_name\n",
    "correlations_dict[groupby]['linkage']   = adata_train.uns['dendrogram_leiden_2.0']['linkage']\n",
    "\n",
    "''' Cluster Purity '''\n",
    "if 'NYU' in hovernet_csv:\n",
    "    file_name = h5_additional_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s_%s_hovernet' % (groupby.replace('.', 'p'), fold_number, meta_folder)\n",
    "else:\n",
    "    file_name = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s_%s_hovernet' % (groupby.replace('.', 'p'), fold_number, meta_folder)\n",
    "critical_coef, critical_ref, p_values, mask = ks_test_cluster_purities(cluster_anno_df=annotated_df, fields=cell_names, groupby=groupby, fold_number=fold_number,\n",
    "                                                                       directory=main_cluster_path, file_name=file_name, p_th=pval_th, critical_values_flag=False)\n",
    "correlations_dict['hovernet'] = dict()\n",
    "correlations_dict['hovernet']['file_name'] = file_name\n",
    "correlations_dict['hovernet']['data']      = critical_coef, critical_ref, p_values, mask\n",
    "\n",
    "''' Immune Landscape '''\n",
    "file_name = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s_%s_immunelandscape' % (groupby.replace('.', 'p'), fold_number, meta_folder)\n",
    "all_data_rho, all_data_pval, mask, _ = correlate_clusters_annotation(slide_rep_df=complete_df, annotations_df=immune_landscape_df, purity_field=meta_field,\n",
    "                                                                     matching_field=corr_matching, corr_method=corr_method, pval_th=pval_th, field_th=0.05*len(features),\n",
    "                                                                     groupby=groupby, fold_number=fold_number, directory=main_cluster_path, file_name=file_name)\n",
    "correlations_dict['immunelandscape'] = dict()\n",
    "correlations_dict['immunelandscape']['file_name'] = file_name\n",
    "correlations_dict['immunelandscape']['data']      = all_data_rho, all_data_pval, mask\n",
    "\n",
    "''' Tile Histological Subtype Annotation '''\n",
    "if additional_complete_df is not None:\n",
    "    file_name = h5_additional_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s_%s_histsubtypes_anno' % (groupby.replace('.', 'p'), fold_number, meta_folder)\n",
    "    p_values, strength, mask = cluster_purity_hypergeom(histo_complete_df, frame_clusters, groupby, 'histtype', pval_th=pval_th, pvalue_as_strengh=False)\n",
    "    strength.index = strength.index.astype(str)\n",
    "    correlations_dict['tile_histsubtypes'] = dict()\n",
    "    correlations_dict['tile_histsubtypes']['file_name'] = file_name\n",
    "    correlations_dict['tile_histsubtypes']['data']     = p_values, strength, mask\n",
    "\n",
    "''' WSI Rep. Cluster Correlations '''\n",
    "file_name     = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s_%s_contentcorr' % (groupby.replace('.', 'p'), fold_number, meta_folder)\n",
    "all_data_rho, all_data_pval, mask = correlate_clusters_occurrance_annotation(complete_df, meta_field, groupby, fold_number, main_cluster_path, file_name,\n",
    "                                                                             corr_method=corr_method, pval_th=pval_th)\n",
    "\n",
    "correlations_dict['content_corr'] = dict()\n",
    "correlations_dict['content_corr']['file_name'] = file_name\n",
    "correlations_dict['content_corr']['data']     = all_data_rho, all_data_pval, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper figures - Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing\n",
      "executing\n"
     ]
    }
   ],
   "source": [
    "p_th = 0.05\n",
    "\n",
    "''' Leiden Dendrogram '''\n",
    "file_name = correlations_dict[groupby]['file_name']\n",
    "plot_dendrogram(adata_train, groupby, directory=figure_path, file_name=file_name+'.png', show=False)\n",
    "\n",
    "''' Cluster Purity '''\n",
    "file_name = correlations_dict['hovernet']['file_name']\n",
    "critical_coef, critical_ref, p_values, mask = correlations_dict['hovernet']['data']\n",
    "g = plot_clustermap(all_data_rho=np.round(critical_coef,2), mask=mask.values, x_label='Cluster', y_label='Cell Annotations', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df,\n",
    "                directory=figure_path, file_name=file_name+'.jpg', figsize=(60,30))\n",
    "correlations_dict['hovernet']['linkage'] = g.dendrogram_col.linkage\n",
    "\n",
    "''' Immune Landscape '''\n",
    "file_name = correlations_dict['immunelandscape']['file_name']\n",
    "all_data_rho, all_data_pval, mask = correlations_dict['immunelandscape']['data']\n",
    "g = plot_clustermap(all_data_rho=all_data_rho, mask=mask.values, x_label='Cluster', y_label='Immune feature', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df,\n",
    "                    directory=figure_path, file_name=file_name+'.jpg', figsize=(65,35))\n",
    "correlations_dict['immunelandscape']['linkage'] = g.dendrogram_col.linkage\n",
    "\n",
    "'''Tile Histological Subtype Annotations'''\n",
    "if additional_complete_df is not None:\n",
    "    file_name = correlations_dict['tile_histsubtypes']['file_name']\n",
    "    p_values, strength, mask = correlations_dict['tile_histsubtypes']['data']\n",
    "    g = plot_clustermap(all_data_rho=strength.transpose(), mask=mask.values.transpose(), vcenter=1, x_label='Cluster', y_label='Histological subtype', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df,\n",
    "                        fmt='.1f', directory=figure_path, file_name=file_name+'.jpg', figsize=(60,30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''Cross Dendrogram - Immune/HoverNet & HoverNet/Immune '''\n",
    "file_name = correlations_dict['hovernet']['file_name'] + '_cross_immune'\n",
    "critical_coef, critical_ref, p_values, mask = correlations_dict['hovernet']['data']\n",
    "g = plot_clustermap(all_data_rho=np.round(critical_coef,2), mask=mask.values, x_label='Cluster', y_label='Cell Annotations', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df,\n",
    "                    col_linkage=correlations_dict['immunelandscape']['linkage'], directory=figure_path, file_name=file_name+'.jpg', figsize=(60,30))\n",
    "\n",
    "file_name = correlations_dict['immunelandscape']['file_name'] + '_cross_hovernet'\n",
    "all_data_rho, all_data_pval, mask = correlations_dict['immunelandscape']['data']\n",
    "g = plot_clustermap(all_data_rho=all_data_rho, mask=mask.values, x_label='Cluster', y_label='Immune feature', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df,\n",
    "                    col_linkage=correlations_dict['hovernet']['linkage'], directory=figure_path, file_name=file_name+'.jpg', figsize=(65,35))\n",
    "\n",
    "'''Cross Dendrogram - Immune/Leiden & HoverNet/Leiden '''\n",
    "file_name = correlations_dict['hovernet']['file_name'] + '_cross_leiden'\n",
    "critical_coef, critical_ref, p_values, mask = correlations_dict['hovernet']['data']\n",
    "g = plot_clustermap(all_data_rho=np.round(critical_coef,2), mask=mask.values, x_label='Cluster', y_label='Cell Annotations', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df,\n",
    "                    col_linkage=leiden_linkage, directory=figure_path, file_name=file_name+'.jpg', figsize=(60,30))\n",
    "\n",
    "file_name = correlations_dict['immunelandscape']['file_name'] + '_cross_leiden'\n",
    "all_data_rho, all_data_pval, mask = correlations_dict['immunelandscape']['data']\n",
    "g = plot_clustermap(all_data_rho=all_data_rho, mask=mask.values, x_label='Cluster', y_label='Immune feature', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df,\n",
    "                    col_linkage=leiden_linkage, directory=figure_path, file_name=file_name+'.jpg', figsize=(65,35))\n",
    "\n",
    "'''Cross Dendrogram - Tile Annotation/Immune & Tile Annotation/HoverNet/Leiden '''\n",
    "if additional_complete_df is not None:\n",
    "    file_name = correlations_dict['tile_histsubtypes']['file_name'] + '_cross_immune'\n",
    "    p_values, strength, mask = correlations_dict['tile_histsubtypes']['data']\n",
    "    g = plot_clustermap(all_data_rho=strength.transpose(), mask=mask.values.transpose(), vcenter=1, x_label='Cluster', y_label='Histological subtype', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df, fmt='.1f', col_linkage=correlations_dict['immunelandscape']['linkage'], directory=figure_path, file_name=file_name+'.jpg', figsize=(60,30))\n",
    "\n",
    "    file_name = correlations_dict['tile_histsubtypes']['file_name'] + '_cross_leiden'\n",
    "    g = plot_clustermap(all_data_rho=strength.transpose(), mask=mask.values.transpose(), vcenter=1, x_label='Cluster', y_label='Histological subtype', cox_os_clusters=coef_os_df, cox_pfs_clusters=coef_pfs_df, fmt='.1f', col_linkage=leiden_linkage, directory=figure_path, file_name=file_name+'.jpg', figsize=(60,30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper figures - Cell Type Enrichment Hover-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_hist(ax, data, cell_name, title, fontsize, fontsize_title, color, stat='density', kde=True, fill=True, cumulative=False, bins=75):\n",
    "    ax = sns.histplot(data, stat=stat, kde=kde, element='step', cumulative=cumulative, fill=fill, ax=ax, color=color)\n",
    "    ax.set_title(title,           fontweight='bold', fontsize=fontsize_title)\n",
    "    ax.set_xlabel('Number %s\\nper tile' % cell_name, fontweight='bold', fontsize=fontsize_title)\n",
    "    ax.set_ylabel('Density',      fontweight='bold', fontsize=fontsize_title)\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "def plot_cumulative_comparison(data_1, data_2, cell_name, title, fontsize, fontsize_title, ax, lw=4, markersize=4):\n",
    "    min_value  = min(data_1.min(), data_2.min())\n",
    "    max_value  = max(data_1.max(), data_2.max())\n",
    "\n",
    "    hist_1, bin_1 = np.histogram(data_1, bins=75, range=[min_value, max_value], density=True)\n",
    "    hist_2, bin_2 = np.histogram(data_2, bins=75, range=[min_value, max_value], density=True)\n",
    "    cum_1 = np.cumsum(hist_1 * np.diff(bin_1))\n",
    "    cum_2 = np.cumsum(hist_2 * np.diff(bin_1))\n",
    "\n",
    "    index    = np.argmax(np.abs(cum_1-cum_2))\n",
    "    index   += 1\n",
    "    x_value  = [bin_1[index]]\n",
    "    y_value  = [(cum_1[index], cum_2[index])]\n",
    "\n",
    "    if max(cum_1[index],cum_2[index])==cum_2[index]:\n",
    "        text = ax.annotate(r'$\\bf{+D_{n,m}}$', (x_value[0]+0.02*max_value, min(cum_1[index],cum_2[index])-0.01), fontweight='bold', fontsize=fontsize_title)\n",
    "    else:\n",
    "        text = ax.annotate(r'$\\bf{-D_{n,m}}$', (x_value[0]+0.02*max_value, min(cum_1[index],cum_2[index])-0.01), fontweight='bold', fontsize=fontsize_title)\n",
    "\n",
    "    lines = []\n",
    "    for i, j in zip(x_value, y_value):\n",
    "        pair = [(i, j[0]), (i, j[1])]\n",
    "        lines.append(pair)\n",
    "\n",
    "    ax.plot(bin_1[:-1], cum_1, color='blue', lw=lw)\n",
    "    ax.plot(bin_1[:-1], cum_2, color='red', lw=lw)\n",
    "    ax.plot(x_value, [i for (i,j) in y_value], 'bs', markersize=markersize)\n",
    "    ax.plot(x_value, [j for (i,j) in y_value], 'ro', markersize=markersize)\n",
    "\n",
    "    linecoll = matcoll.LineCollection(lines, colors='k', linestyle='--', lw=lw)\n",
    "    ax.add_collection(linecoll)\n",
    "\n",
    "    ax.set_title(title,           fontweight='bold', fontsize=fontsize_title)\n",
    "    ax.set_xlabel('Number %s\\nper tile' % cell_name, fontweight='bold', fontsize=fontsize_title)\n",
    "    ax.set_ylabel('Density',      fontweight='bold', fontsize=fontsize_title)\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "    # adjust_text([text])\n",
    "\n",
    "def plot_comparison(cluster_anno_df, cell_name, cluster_id_1, fontsize, fontsize_title, stat='density', fill=True, cumulative=False, cluster_id_2=None, lw=6, markersize=6,\n",
    "                    bins=75, figsize=(10,4)):\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=1, sharex=True, sharey=False, figsize=figsize)\n",
    "\n",
    "    title_1 = 'HPC %s\\nProbability Distribution' % cluster_id_1\n",
    "    data_1  = cluster_anno_df[cluster_anno_df[groupby]==cluster_id_1][cell_name].values\n",
    "\n",
    "    if cluster_id_2 is None:\n",
    "        title_2 = 'All HPCs\\nProbability Distribution'\n",
    "        data_2  = cluster_anno_df[cell_name].values\n",
    "    else:\n",
    "        title_2 = 'HPC %s\\nProbability Distribution' % cluster_id_2\n",
    "        data_2  = cluster_anno_df[cluster_anno_df[groupby]==cluster_id_2][cell_name].values\n",
    "\n",
    "    plot_hist(ax[0], data_1, cell_name, title_1, fontsize, fontsize_title, color='blue', stat=stat, cumulative=cumulative, fill=fill, bins=bins)\n",
    "    plot_hist(ax[1], data_2, cell_name, title_2, fontsize, fontsize_title, color='red',  stat=stat, cumulative=cumulative, fill=fill, bins=bins)\n",
    "\n",
    "    range_0 = ax[0].get_ylim()\n",
    "    range_1 = ax[1].get_ylim()\n",
    "    if range_0[1] > range_1[1]:\n",
    "        final_range = range_0\n",
    "    else:\n",
    "        final_range = range_1\n",
    "    ax[0].set_ylim(final_range)\n",
    "    ax[1].set_ylim(final_range)\n",
    "\n",
    "    # Cumulative\n",
    "    title = 'Cumulative\\nDistribution'\n",
    "    # plot_hist(ax[2], data_1, title, fontsize, fontsize_title, color='blue',  stat=stat, kde=False, cumulative=True, fill=False, bins=bins)\n",
    "    # plot_hist(ax[2], data_2, title, fontsize, fontsize_title, color='red',   stat=stat, kde=False, cumulative=True, fill=False, bins=bins)\n",
    "    plot_cumulative_comparison(data_1, data_2, cell_name, title, fontsize, fontsize_title, ax=ax[2], lw=lw, markersize=markersize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "figsize         = (20,6)\n",
    "fontsize_title = 20\n",
    "fontsize       = 15\n",
    "bins           = 75\n",
    "\n",
    "cell_name    = cell_names[0]\n",
    "cluster_id_1 = 10\n",
    "plot_comparison(cluster_anno_df, cell_name, cluster_id_1, fontsize, fontsize_title, lw=3, markersize=7, stat='density', cumulative=False, cluster_id_2=None, bins=bins, figsize=figsize)\n",
    "\n",
    "cluster_id_1 = 15\n",
    "plot_comparison(cluster_anno_df, cell_name, cluster_id_1, fontsize, fontsize_title, lw=3, markersize=7, stat='density', cumulative=False, cluster_id_2=None, bins=bins, figsize=figsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper figures - Scatter Plot correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frames_perc = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path, 'percent', 100)\n",
    "complete_df_perc, additional_complete_df, frame_clusters, frame_samples, features = frames_perc\n",
    "\n",
    "frames_clr = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path, 'clr', 100)\n",
    "complete_df_clr,  additional_complete_df, frame_clusters, frame_samples, features = frames_clr\n",
    "\n",
    "cross_df_perc = pd.merge(complete_df_perc, immune_landscape_df, left_on='samples', right_on='samples', how='inner')\n",
    "cross_df_clr  = pd.merge(complete_df_clr,  immune_landscape_df, left_on='samples', right_on='samples', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_correlation_scatter(cross_df, cluster, annotations, all_data_rho, all_data_pval, fontsize_labels=22, fontsize_title=30):\n",
    "    from decimal import Decimal\n",
    "    cross_df.columns = cross_df.columns.astype(str)\n",
    "\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        rho_annotation  = all_data_rho.loc[annotation, str(cluster)]\n",
    "        pval_annotation = all_data_pval.loc[annotation, str(cluster)]\n",
    "        g = sns.jointplot(data=cross_df, x=annotation, y=str(cluster), kind='reg', ci=None, height=10, ratio=2)\n",
    "        g.ax_joint.set_ylabel('HPC %s\\nContribution' % cluster, fontsize=fontsize_labels, fontweight='bold')\n",
    "        g.ax_joint.set_xlabel(annotation, fontsize=fontsize_labels, fontweight='bold')\n",
    "\n",
    "        for tick in g.ax_joint.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for tick in g.ax_joint.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            g.ax_joint.spines[axis].set_linewidth(4)\n",
    "            g.ax_marg_x.spines[axis].set_linewidth(4)\n",
    "            g.ax_marg_y.spines[axis].set_linewidth(4)\n",
    "\n",
    "        plt.suptitle('Spearman %s=%s\\np-value=%s' % (r'$\\mathbf{\\rho}$', np.round(rho_annotation, 1), '%.1E' % Decimal(pval_annotation)), fontsize=fontsize_title, fontweight='bold')\n",
    "        g.fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "cross_df_plt = cross_df_clr.copy(deep=True)\n",
    "cross_df_plt['Th2 Cells'] /= 1000\n",
    "cross_df_plt = cross_df_plt.rename(columns={'Th2 Cells':'Th2 Cells (Thousands)'})\n",
    "\n",
    "all_data_rho_plt  = all_data_rho.rename(index={'Th2 Cells':'Th2 Cells (Thousands)'})\n",
    "all_data_pval_plt = all_data_pval.rename(index={'Th2 Cells':'Th2 Cells (Thousands)'})\n",
    "\n",
    "all_data_rho, all_data_pval, mask = correlations_dict['immunelandscape']['data']\n",
    "annotations = ['TIL Regional Fraction', 'Lymphocyte Infiltration Signature Score', 'Leukocyte Fraction']\n",
    "show_correlation_scatter(cross_df_plt, cluster=1, annotations=annotations, all_data_rho=all_data_rho_plt, all_data_pval=all_data_pval_plt)\n",
    "# show_correlation_scatter(cross_df_clr, cluster=31, annotations=annotations, all_data_rho=all_data_rho_plt, all_data_pval=all_data_pval_plt)\n",
    "\n",
    "annotations = ['Proliferation', 'Wound Healing', 'Th2 Cells (Thousands)']\n",
    "# show_correlation_scatter(cross_df_plt, cluster=14, annotations=annotations, all_data_rho=all_data_rho_plt, all_data_pval=all_data_pval_plt)\n",
    "# show_correlation_scatter(cross_df_plt, cluster=15, annotations=annotations, all_data_rho=all_data_rho_plt, all_data_pval=all_data_pval_plt)\n",
    "# show_correlation_scatter(cross_df_clr, cluster=11, annotations=annotations, all_data_rho=all_data_rho_plt, all_data_pval=all_data_pval_plt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
